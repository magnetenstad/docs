<!DOCTYPE html>
<html>
  <head>
    <!-- Katex -->
    <link rel="stylesheet" href=
        "https://cdn.jsdelivr.net/npm/katex/dist/katex.min.css"/>

    <!-- GitHub Markdown Styles -->
    <link rel="stylesheet" href=
        "https://cdn.jsdelivr.net/github-markdown-css/2.2.1/github-markdown.css"/>

    <title>09.md</title>
    <link rel="icon" type="image/x-icon" href="../../../favicon.png"/>

    <!-- Custom Styles -->
    <link rel="stylesheet" href="../../../styles.css">
  
  </head>

  <body class="markdown-body">
    <div class="page flex-row">
      <div class="col links">
        
<p><h4><a href="../index.html">tdt4186/</a><a href="./index.html">lectures</a>
</h4></p>
<ul>
<li>ðŸ“‚ <a href="./assets/index.html">assets</a></li>
<li>ðŸ“„ <a href="01.html">01</a></li>
<li>ðŸ“„ <a href="02.html">02</a></li>
<li>ðŸ“„ <a href="03.html">03</a></li>
<li>ðŸ“„ <a href="04.html">04</a></li>
<li>ðŸ“„ <a href="05.html">05</a></li>
<li>ðŸ“„ <a href="06.html">06</a></li>
<li>ðŸ“„ <a href="07.html">07</a></li>
<li>ðŸ“„ <a href="08.html">08</a></li>
<li>ðŸ“„ <a href="09.html">09 âœ¨</a></li>
<li>ðŸ“„ <a href="10.html">10</a></li>
<li>ðŸ“„ <a href="11.html">11</a></li>
<li>ðŸ“„ <a href="12.html">12</a></li>
<li>ðŸ“„ <a href="13.html">13</a></li>
<li>ðŸ“„ <a href="14.html">14</a></li>
<li>ðŸ“„ <a href="15.html">15</a></li>
<li>ðŸ“„ <a href="16.html">16</a></li>
<li>ðŸ“„ <a href="17.html">17</a></li>
<li>ðŸ“„ <a href="18.html">18</a></li>
<li>ðŸ“„ <a href="19.html">19</a></li>
<li>ðŸ“„ <a href="20.html">20</a></li>
<li>ðŸ“„ <a href="21.html">21</a></li>
<li>ðŸ“„ <a href="22.html">22</a></li>
<li>ðŸ“„ <a href="questions.html">questions</a></li>
</ul>
<p><h4>Table of Contents</h4></p>
<nav class="table-of-contents"><ol><li><a href="#lecture-9%2C-part-1%3A-memory-management">Lecture 9, part 1: Memory management</a><ol><li><a href="#exam">Exam</a></li><li><a href="#resources-(again)">Resources (again)</a></li><li><a href="#multiprogramming-(again)">Multiprogramming (again)</a></li><li><a href="#memory-management-requirements">Memory management requirements</a></li><li><a href="#basic-policies-and-strategies">Basic policies and strategies</a></li><li><a href="#memory-allocation%3A-problem">Memory allocation: problem</a></li><li><a href="#static-memory-allocation">Static memory allocation</a></li><li><a href="#dynamic-memory-allocation">Dynamic memory allocation</a></li><li><a href="#memory-allocation%3A-bit-lists">Memory allocation: bit lists</a></li><li><a href="#memory-allocation%3A-linked-list">Memory allocation: linked list</a><ol><li><a href="#linked-list-in-free-memory">Linked list in free memory</a></li><li><a href="#placement-strategies">Placement strategies</a></li></ol></li><li><a href="#placement-strategies-(2)">Placement strategies (2)</a></li><li><a href="#discussion%3A-fragmentation">Discussion: fragmentation</a></li><li><a href="#use-of-the-different-methods">Use of the different methods</a></li></ol></li><li><a href="#lecture-9%2C-part-2%3A-memory-management-and-mmu-hardware-support">Lecture 9, part 2: Memory management and MMU hardware support</a><ol><li><a href="#multiprogramming%3A-swapping">Multiprogramming: swapping</a></li><li><a href="#swapping-(2)">Swapping (2)</a></li><li><a href="#address-linking-and-relocation">Address linking and relocation</a></li><li><a href="#address-linking-and-relocation-(2)">Address linking and relocation (2)</a></li><li><a href="#address-linking-and-relocation-(3)">Address linking and relocation (3)</a></li><li><a href="#address-linking-and-relocation-(4)">Address linking and relocation (4)</a></li><li><a href="#segmentation">Segmentation</a></li><li><a href="#segmentation-(2)">Segmentation (2)</a></li><li><a href="#segmentation-(3)">Segmentation (3)</a></li><li><a href="#segmentation-(4)">Segmentation (4)</a></li><li><a href="#compaction">Compaction</a></li><li><a href="#paging">Paging</a></li><li><a href="#mmu-with-page-table">MMU with page table</a></li><li><a href="#mmu-with-page-table-(2)">MMU with page table (2)</a></li><li><a href="#segmentation-and-page-addressing">Segmentation and page addressing</a></li><li><a href="#segmentation-and-page-addressing-(2)">Segmentation and page addressing (2)</a></li><li><a href="#paging-1">Paging</a></li><li><a href="#multi-level-page-addressing">Multi-level page addressing</a></li><li><a href="#translation-lookaside-buffer-(tlb)">Translation lookaside buffer (TLB)</a></li><li><a href="#translation-lookaside-buffer-(2)">Translation lookaside buffer (2)</a></li><li><a href="#inverted-page-tables">Inverted page tables</a></li><li><a href="#inverted-page-tables-(2)">Inverted page tables (2)</a></li><li><a href="#conclusion">Conclusion</a></li></ol></li></ol></nav>
      </div>
      <article class="col content">
        
<h1 id="lecture-9%2C-part-1%3A-memory-management" tabindex="-1">Lecture 9, part 1: Memory management</h1>
<p><a href="08.html">Previous lecture</a>
<a href="10.html">Next lecture</a></p>
<p><iframe
width="560" height="315" src="https://www.youtube.com/embed/kXop1DTa68U"
title="YouTube video player"
frameborder="0"
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
allowfullscreen>
</iframe></p>
<p><iframe
width="560" height="315" src="https://www.youtube.com/embed/X9FJf5zn3bc"
title="YouTube video player"
frameborder="0"
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
allowfullscreen>
</iframe></p>
<h2 id="exam" tabindex="-1">Exam</h2>
<p>Main memory as a resource and its management</p>
<p><strong>Important questions:</strong></p>
<ul>
<li>Requirements for memory management for multiprogramming systems?</li>
<li>Which policies and strategies are relevant for memory management?</li>
<li>Can you describe the basic problem of memory allocation?</li>
<li>How does dynamic memory allocation work?
<ul>
<li>Can you describe different approaches, describe pros/cons?</li>
</ul>
</li>
<li>Can you name and describe different placement strategies?</li>
<li>What is memory fragmentation?
<ul>
<li>Which kinds of fragmentation exist, what are their properties?</li>
<li>Where are different allocation methods typically used?</li>
</ul>
</li>
<li>Can you describe differences between swapping, segmentation, paging?
<ul>
<li>How does paging as an OS concept interact with the MMU?</li>
<li>How can paging be optimized using hardware or software approaches?</li>
</ul>
</li>
</ul>
<h2 id="resources-(again)" tabindex="-1">Resources (again)</h2>
<ul>
<li>Tasks of an operating system:
<ul>
<li>Administering the resources of a computer ^6134fb</li>
<li>Creating abstractions that allow applications to easily and efficiently use these resources</li>
</ul>
</li>
<li>So far: processes
<ul>
<li>Concept to abstract from a real CPU</li>
</ul>
</li>
<li>Now: memory
<ul>
<li>Administration of main and background memory (RAM and secondary storage)</li>
</ul>
</li>
</ul>
<h2 id="multiprogramming-(again)" tabindex="-1">Multiprogramming (again)</h2>
<ul>
<li>CPU load under the assumption of a given probability to wait for I/O</li>
<li>Multiprogramming is essential to guarantee a high CPU utilization
<ul>
<li>When processes are started and terminated, memory has to be allocated and released dynamically!</li>
</ul>
</li>
</ul>
<h2 id="memory-management-requirements" tabindex="-1">Memory management requirements</h2>
<ul>
<li>Multiple processes need main memory
<ul>
<li>Processes are located in different positions in main memory</li>
<li>Protection requirements:
<ul>
<li>Protect the OS from processes</li>
<li>Protect processes against accesses from other processes</li>
</ul>
</li>
<li>Size of main memory may not suffice for all processes together</li>
</ul>
</li>
<li>OS has to know about free memory areas, administer and allocate them
<ul>
<li>Swapping of processes</li>
<li>Relocation of instructions in programs</li>
<li>Use hardware support</li>
</ul>
</li>
</ul>
<h2 id="basic-policies-and-strategies" tabindex="-1">Basic policies and strategies</h2>
<ul>
<li>Placement policy
<ul>
<li>Which area of memory should be allocated?
<ul>
<li>The one with the largest/smallest fragmentation?</li>
<li>Not that relevant, since fragmentation is secondary.</li>
</ul>
</li>
</ul>
</li>
<li>Fetch policy
<ul>
<li>When should we swap in memory contents?
<ul>
<li>On demand or predictive</li>
</ul>
</li>
</ul>
</li>
<li>Replacement policy
<ul>
<li>Which memory contents should be swapped out if the system is running out of free memory?
<ul>
<li>The oldest, least used one</li>
<li>The one that is used for the longest amound of time</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="memory-allocation%3A-problem" tabindex="-1">Memory allocation: problem</h2>
<p>The available memory is used by</p>
<ul>
<li>User processes
<ul>
<li>Program code (text)</li>
<li>Program data (data)</li>
<li>Dynamic memory allocations (stack, heap)</li>
</ul>
</li>
<li>Operating system
<ul>
<li>Operating system code and data</li>
<li>Process control blocks</li>
<li>Data buffers for I/O</li>
<li>...</li>
</ul>
</li>
<li>Memory allocation is necessary!</li>
</ul>
<h2 id="static-memory-allocation" tabindex="-1">Static memory allocation</h2>
<ul>
<li>Idea: use fixed memory areas for the OS and for user processes</li>
<li>Problems:
<ul>
<li>Limited degree of multiprogramming</li>
<li>Limitation of other resources e.g. I/O bandwidth due to buffers that are too small</li>
<li>Unused OS memory cannot be used by application processes (and vice versa)</li>
</ul>
</li>
<li>Solution: use dynamic memory allocation</li>
</ul>
<h2 id="dynamic-memory-allocation" tabindex="-1">Dynamic memory allocation</h2>
<ul>
<li>Segments
<ul>
<li>contiguous area of memory</li>
</ul>
</li>
<li>Allocation and release of segments</li>
<li>All the segments that hre part of a program we have seen already:
<ul>
<li>text segment(s)</li>
<li>data segment(s)</li>
<li>stack segment(s) (local variables, parameters, return addresses, ...)</li>
</ul>
</li>
<li>Search for suitable memory areas for allocation
<ul>
<li>especially when a program is started</li>
</ul>
</li>
<li>Placement policies required
<ul>
<li>especially important: management of free memory</li>
</ul>
</li>
</ul>
<h2 id="memory-allocation%3A-bit-lists" tabindex="-1">Memory allocation: bit lists</h2>
<ul>
<li>Free (sometimes also allocated) segments of main memory have to be represented</li>
<li>Simple approach: bit lists
<ul>
<li>Problems:
<ul>
<li>Bit lists can require lots of memory</li>
<li>When releasing memory, the size of the memory block to be released has to be known or provided</li>
<li>Linear search is slow</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="memory-allocation%3A-linked-list" tabindex="-1">Memory allocation: linked list</h2>
<ul>
<li>Representation of used and free segments</li>
<li>Problem:
<ul>
<li>Memory required for the list has to be allocated (dynamically)</li>
</ul>
</li>
</ul>
<h3 id="linked-list-in-free-memory" tabindex="-1">Linked list in <em>free memory</em></h3>
<ul>
<li>A minimum gap size has to be guaranteed to store the length of and the pointer to the next free gap!</li>
<li>Problem:
<ul>
<li>To increase efficieny, backwards links might be required in addition</li>
<li>This representation is dependent on the allocation strategy</li>
</ul>
</li>
</ul>
<h3 id="placement-strategies" tabindex="-1">Placement strategies</h3>
<p>...based on different sorting policies for the list of gaps:</p>
<ul>
<li>First fit (sorted after memory address)
<ul>
<li>use the first fitting gap</li>
</ul>
</li>
<li>Rotating First Fit / Next Fit
<ul>
<li>Like first fit, but start with the most recently allocated gap</li>
<li>avoids the generation of a large number of small gaps at the beginning of the list</li>
</ul>
</li>
<li>Best Fit (sorted after gap size - smallest first)
<ul>
<li>find the smallest fitting gap</li>
</ul>
</li>
<li>Worst Fit (sorted after gap size - largest first)
<ul>
<li>find the largest fitting gap</li>
</ul>
</li>
<li>Problems:
<ul>
<li>gaps that are too small, fragmentation</li>
</ul>
</li>
</ul>
<h2 id="placement-strategies-(2)" tabindex="-1">Placement strategies (2)</h2>
<ul>
<li>Buddy method: split memory dynamically into areas of a size 2^n^</li>
</ul>
<p><img src="assets/2022-05-02-10-25-51.png" alt=""></p>
<h2 id="discussion%3A-fragmentation" tabindex="-1">Discussion: fragmentation</h2>
<ul>
<li>External fragmentation
<ul>
<li>Allocations creates memory fragments outside of the allocated memory areas which cannot be used</li>
<li>Problems with all list based strategies, e.g. first fit, best fit ...</li>
</ul>
</li>
<li>Internal fragmentation
<ul>
<li>Unused memory inside of allocated memory areas</li>
<li>Problem e.g. with the buddy allocator
<ul>
<li>since request sizes are rounded up to the next power of two</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="use-of-the-different-methods" tabindex="-1">Use of the different methods</h2>
<ul>
<li>In the operating system (kernel) itself
<ul>
<li>Management of system memory</li>
<li>Allocation of memory to processes and the operating system itself</li>
<li>e.g. Buddy allocator in Linux</li>
</ul>
</li>
<li>Inside of processes
<ul>
<li>Management of heap memory</li>
<li>Enables dynamic allocation of memory areas by the process (using the malloc und free libc functions)</li>
<li>Typically using linked lists</li>
</ul>
</li>
<li>Areas of secondary storage
<ul>
<li>Management of certain sections of secondary memory
<ul>
<li>e.g. the area used for process swapping (swap space)</li>
</ul>
</li>
<li>Often using bitmaps</li>
</ul>
</li>
</ul>
<h1 id="lecture-9%2C-part-2%3A-memory-management-and-mmu-hardware-support" tabindex="-1">Lecture 9, part 2: Memory management and MMU hardware support</h1>
<h2 id="multiprogramming%3A-swapping" tabindex="-1">Multiprogramming: swapping</h2>
<ul>
<li>Segments of a process are swapped out to background memory and released in main memory
<ul>
<li>e.g. if I/O waiting times hinder a process from running</li>
</ul>
</li>
<li>Segments are swapped in back into main memory when the waiting time ends</li>
<li>Large amount of time required for swapping in and out
<ul>
<li>Latency of the disk (e.g. positioning og a read/write head of a hard disk, not a big problem with SSDs)</li>
<li>Transfer time</li>
</ul>
</li>
</ul>
<h2 id="swapping-(2)" tabindex="-1">Swapping (2)</h2>
<ul>
<li>Addresses in processes are usually linked statically
<ul>
<li>Can only be swapped into the same location in main memory</li>
<li>Collisions with new segments allocated in memory after the process was swapped out</li>
</ul>
</li>
<li>Possible solution: partitioning of main memory
<ul>
<li>Only one process per partition</li>
<li>Swapping in into the same partition as before</li>
<li>Memory cannot be used optimally</li>
</ul>
</li>
<li>Better approach: dynamic allocation and program relocation</li>
</ul>
<h2 id="address-linking-and-relocation" tabindex="-1">Address linking and relocation</h2>
<ul>
<li>Problem: Machine instructions use addresses
<ul>
<li>e.g. a jump instruction that changes control flow into a function</li>
<li>or a load instruction to read a variable value from the data segment</li>
</ul>
</li>
<li>Different approaches to link the adrress used as the operand of an instuction:
<ul>
<li>Absolute linking (at compile/link time)
<ul>
<li>Addresses are fixed</li>
<li>The program can only execute correctly at a certain location in memory</li>
</ul>
</li>
<li>Static linking (at load time)
<ul>
<li>Absolute addresses are adapted (relocated) when a program is loaded (started)</li>
<li>Relocation information has to be provided by the compiler/assembler</li>
</ul>
</li>
<li>Dynamic linking (at execution time)
<ul>
<li>Code accesses operands only indirectly</li>
<li>The program can be relocated in memory at any time</li>
<li>Resulting programs are slightly larger and slower</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="address-linking-and-relocation-(2)" tabindex="-1">Address linking and relocation (2)</h2>
<ul>
<li>Translation process (creation of relocation information)</li>
</ul>
<p><img src="assets/lecture.9b.translation.png" alt=""></p>
<h2 id="address-linking-and-relocation-(3)" tabindex="-1">Address linking and relocation (3)</h2>
<p><img src="assets/lecture.9b.linking_and_loading.png" alt=""></p>
<h2 id="address-linking-and-relocation-(4)" tabindex="-1">Address linking and relocation (4)</h2>
<ul>
<li>Relocation information in the linker module (object file)
<ul>
<li>allows the linking of modules into arbitrary programs</li>
</ul>
</li>
<li>Relocation information in the loader module
<ul>
<li>allows loading of the program at arbitrary locations in memory</li>
<li>absolute addresses are generated only at load time</li>
</ul>
</li>
<li>Dynamic linking with compiler support
<ul>
<li>Program does not use absolute addresses and can thus always be loaded to arbitrary memory locations
<ul>
<li>position independent code (PIC)</li>
</ul>
</li>
</ul>
</li>
<li>Dynamic linking with MMU support
<ul>
<li>What modern computers usually do</li>
<li>Mapping from "logical" to "physical" addresses
<ul>
<li>Relocation at link time is sufficient (except for shared libraries)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="segmentation" tabindex="-1">Segmentation</h2>
<ul>
<li>Hardware support: map logical to physical addresses</li>
<li>The segment in the logical address space can be located at an arbitrary position in the physical space</li>
<li>The OS controls where a segment is located in physical memory</li>
</ul>
<h2 id="segmentation-(2)" tabindex="-1">Segmentation (2)</h2>
<ul>
<li>Using a translation table (per process)</li>
</ul>
<p><img src="assets/lecture.9b.segment_table.png" alt=""></p>
<h2 id="segmentation-(3)" tabindex="-1">Segmentation (3)</h2>
<ul>
<li>Hardware component translating addresse: MMU (Memory Management Unit)</li>
<li>Protects against overstepping the segment limits
<ul>
<li>MMU checks read/write/execute permissions</li>
<li>Trap indicates a violation (a process attempts to access non permitted memory location)</li>
<li>Programs and operating system are protected against each other</li>
</ul>
</li>
<li>Process switching by exchanging the segment base
<ul>
<li>each process has its own translation table</li>
</ul>
</li>
<li>Easier swapping
<ul>
<li>after swapping a process into an arbitrary memory location, only the translation table has to be modified</li>
</ul>
</li>
<li>Shared segments are possible
<ul>
<li>Instruction (text) segments</li>
<li>Data segments (shared memory)</li>
</ul>
</li>
</ul>
<h2 id="segmentation-(4)" tabindex="-1">Segmentation (4)</h2>
<p>Problems...</p>
<ul>
<li>Fragmentation of main memory due to frequent swapping or starting/termination of processes
<ul>
<li>This results in small unusable gaps: external fragmentation</li>
</ul>
</li>
<li>Compacting helps
<ul>
<li>Segments are moved to close gaps</li>
<li>Segment table is modified accordingly</li>
<li>Time consuming..</li>
</ul>
</li>
<li>Long running I/O operations required for swapping
<ul>
<li>Not all parts of a segment are used with the same frequency</li>
</ul>
</li>
</ul>
<h2 id="compaction" tabindex="-1">Compaction</h2>
<ul>
<li>Moving of segments
<ul>
<li>Creates fewer but larger gaps</li>
<li>Reduced fragmentation</li>
<li>Operation with large overhead
<ul>
<li>Specific overhead depends on the size of the segments that are moved</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="assets/lecture.9b.compaction.png" alt=""></p>
<h2 id="paging" tabindex="-1">Paging</h2>
<ul>
<li>Logical address space is split into pages of identical size
<ul>
<li>Pages can be located at arbitrary positions in the physical memory address space</li>
<li>Solves the fragmentation problem</li>
<li>No compaction necessary</li>
<li>Simplified memory allocation and swapping</li>
</ul>
</li>
</ul>
<h2 id="mmu-with-page-table" tabindex="-1">MMU with page table</h2>
<ul>
<li>A table is used to translate page addresses into page frame addresses</li>
</ul>
<p><img src="assets/lecture.9b.page_table.png" alt=""></p>
<h2 id="mmu-with-page-table-(2)" tabindex="-1">MMU with page table (2)</h2>
<ul>
<li>Page-based addressing creates internal fragmentation
<ul>
<li>The last page is often not used completely</li>
</ul>
</li>
<li>Page size
<ul>
<li>small pages reduce internal fragmentation, but increase the size of the page table (and vice versa)</li>
<li>common page size: 512 bytes - 8192 bytes</li>
</ul>
</li>
<li>Page tables are large and have to be kept in main memory</li>
<li>Large number of implicit page accesses required to map an address</li>
<li>Only one "segment" per context
<ul>
<li>Makes the "appropriate" use of memory difficult to control
<ul>
<li>e.g. ensuring push/pop only on "stack", execution only of "text"</li>
</ul>
</li>
</ul>
</li>
</ul>
<blockquote>
<p>-&gt; Combine paging with segmentation</p>
</blockquote>
<h2 id="segmentation-and-page-addressing" tabindex="-1">Segmentation and page addressing</h2>
<p><img src="assets/lecture.9b.segmentation_and_page_addressing.png" alt=""></p>
<h2 id="segmentation-and-page-addressing-(2)" tabindex="-1">Segmentation and page addressing (2)</h2>
<ul>
<li>This requires even more implicit memory accesses</li>
<li>Large tables in main memory</li>
<li>Mixup of the different concepts</li>
<li>Still swapping of complete segments</li>
</ul>
<blockquote>
<p>-&gt; Multi-level page addressing with paging</p>
</blockquote>
<h2 id="paging-1" tabindex="-1">Paging</h2>
<ul>
<li>Swapping complete segments is not necessary
<ul>
<li>Single pages can now be swapped (paged)</li>
</ul>
</li>
<li>Hardware support
<ul>
<li>If the presence bit is set, nothing changes</li>
<li>If the presence bit is cleared, a trap is invoked (page fault)</li>
<li>The trap handler (part of the OS) can now initiate the loading of the page from background storage (this requires hardware support in the CPU)</li>
</ul>
</li>
</ul>
<h2 id="multi-level-page-addressing" tabindex="-1">Multi-level page addressing</h2>
<ul>
<li>Example: two-level page addressing</li>
</ul>
<p><img src="assets/lecture.9b.multi-level_page_addressing.png" alt=""></p>
<ul>
<li>Presence bit also for all entries in higher levels
<ul>
<li>This enable the swapping of page tables</li>
<li>Tables can be created at access time (on demand) - saves memory!</li>
</ul>
</li>
<li>However: even more implicit memory addresses required</li>
</ul>
<h2 id="translation-lookaside-buffer-(tlb)" tabindex="-1">Translation lookaside buffer (TLB)</h2>
<ul>
<li>Fast cache which is consulted before a (possible) lookup in the page table</li>
</ul>
<p><img src="assets/lecture.9b.tlb.png" alt=""></p>
<h2 id="translation-lookaside-buffer-(2)" tabindex="-1">Translation lookaside buffer (2)</h2>
<ul>
<li>Fast access to page address mapping, if the information is contained in the (fully associative) TLB memory
<ul>
<li>No implicit page accesses required</li>
</ul>
</li>
<li>TLB has to be flushed when the OS switches context</li>
<li>If a page not contained in the TLB is accessed, the related access information is entered into the TLB
<ul>
<li>An old TLB entry has to be selected to be replaced by the new one</li>
</ul>
</li>
<li>TLB sizes:
<ul>
<li>Intel Core i7: 512 entries, page size 4 kB</li>
<li>UltraSPARC T2: data TLB = 128, Code TLB = 64, page size 8 kB</li>
<li>Larger TLBs are currently not implemented due to timing and cost considerations</li>
</ul>
</li>
</ul>
<h2 id="inverted-page-tables" tabindex="-1">Inverted page tables</h2>
<ul>
<li>For large logical address spaces (e.g. 64 bit addresses)
<ul>
<li>Classical page tables are very large or</li>
<li>Large number of address translation levels</li>
<li>Page tables are often only sparsely populated</li>
</ul>
</li>
</ul>
<blockquote>
<p>-&gt; Inverted Page Tables</p>
</blockquote>
<p><img src="assets/lecture.9b.inverted_page_table.png" alt=""></p>
<h2 id="inverted-page-tables-(2)" tabindex="-1">Inverted page tables (2)</h2>
<ul>
<li>Advantages
<ul>
<li>Required little memory space to store address mappings</li>
<li>Table can always be kept in main memory</li>
</ul>
</li>
<li>Disadvantages
<ul>
<li>Sharing of page frames is difficult to implement</li>
<li>Process-local data structures are used for pages that are swapped out</li>
<li>Lookups in the page table have large overhead
<ul>
<li>Use of associative memories and hash functions</li>
</ul>
</li>
</ul>
</li>
<li>Despite these disadvantages, many 64 bit processors use this approach to address translation:
<ul>
<li>Sun UltraSparc, IBM PowerPC, intel Itanium (IA-64), (DEC Alpha), ...</li>
<li>But these are not in much use today</li>
</ul>
</li>
</ul>
<h2 id="conclusion" tabindex="-1">Conclusion</h2>
<ul>
<li>The OS has to work in close cooperation with the hardware to enable efficient memory management
<ul>
<li>Segmentation and/or page-based addressing</li>
<li>The implicit indirection of memory accesses allows to arbitrarily move code and data of running processes under the control of the OS (at page size granularity)</li>
</ul>
</li>
<li>Additional strategic decisions have to be taken
<ul>
<li>Placement strategy (first fit, best fit, buddy, ...)
<ul>
<li>These differ with regard to fragmentation and the required overhead from allocation and release</li>
<li>Selection of an appropriate strategy depends on the expected application profile</li>
</ul>
</li>
<li>When swapping segments or pages:
<ul>
<li>Loading strategy</li>
<li>Replacement strategy</li>
</ul>
</li>
</ul>
</li>
</ul>

        <div style="height: 100vh;"></div>
      </article>
      </div>
  </body>
</html>
